python3 ../train.py \
  --device "cuda:0" \
  --epochs 50 \
  --batch_size 64 \
  --drop_prob 0.1 \
  --clip_lr 1e-5 \
  --fin_tuning_lr 5e-5 \
  --downs_en_lr 1.2e-4 \
  --weight_decay_rate 0.01 \
  --clip_grad 1.0 \
  --warmup_prop 0.08 \
  --gradient_accumulation_steps 2 \
  --patience 1e-5 \
  --patience_num 20 \
  --text_encoder "roberta-base" \
  --image_encoder "clip-patch32" \
  --dataset_name "twitter2015" \
  --ex_project "mner_experiment" \
  --ex_name "use_images_model" \
  --ex_nums "A0" \
  --use_bilstm \
  --use_image \
  --align_lambda 0.4 \
  --nce_lambda 0.02 \
  --preserve_lambda 0.05 \
  --sparsity_lambda 0.01 \
  --resampler_tokens 8 \
  --emission_temperature 2.5 \
  --align_warmup_epochs 5 \
  --image_dropout_p 0.3 \
  --vision_trainable \
  --unfreeze_last_vision_blocks 2